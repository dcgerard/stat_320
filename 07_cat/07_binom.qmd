---
title: "Categorical Tests"
author: "David Gerard"
format: html
date: today
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
            fig.width = 4, 
            fig.height = 3, 
            fig.align = "center")
ggplot2::theme_set(ggplot2::theme_bw() + ggplot2::theme(strip.background = ggplot2::element_rect(fill = "white")))
```

```{r}
library(broom)
```


# Two-sample Binomial Test

-   We have the following 2x2 contingency table from a study comparing age of a mother at her first birth against breast cancer status. The hypothesis is that women who have their first births later in life are at higher risks of breast cancer.
  
    ```{r}
    #| message: false
    #| echo: false
    library(tidyverse)
    library(janitor)
    library(gt)
    
    tribble(~Age, ~Case, ~Control,
            "≥30", 683, 1498,
            "≤29", 2537, 8747) |>
      as_tabyl() |>
      adorn_totals(c("col", "row")) |>
      gt(rowname_col = "Age") |>
      tab_spanner(
        columns = Case:Control, # select all columns except the row variable
        label = "Status" # the name to display
      ) |>
      tab_stubhead(         # add row variable header
        label = "Age at First Birth" 
      ) 
    ```

-   Let $n_1 = 3220$ and $n_2 = 10245$ be the sample sizes among case and control women, respectively. 

-   Let $x_1 = 683$ and $x_2 = 1498$ be the number of women older than 30 at first birth for case and control women, respectively. 

-   Our model is the $X_1 \sim \text{Binom}(n_1, p_1)$ and $X_2 \sim \text{Binom}(n_2, p_2)$.

-   Our hypotheses are
    - $H_0$: $p_1 = p_2$
    - $H_1$: $p_1 \neq p_2$

-   You can run this test in R via

    ```{r}
    prop.test(x = c(683, 1498), n = c(3220, 10245)) |>
      tidy()
    ```

-   If we did this manually (which you will only do for exams and homeworks, not in real life), we first calculate the estimated proportions

    ```{r}
    p1hat <- 683 / 3220
    p2hat <- 1498 / 10245
    ```

-   We then calculate the pooled estimated proportion, which is our estimate if the null is true

    ```{r}
    phat <- (683 + 1498) / (3220 + 10245)
    ```

-   Our test statistic (I'm skipping the continuity correction)

    ```{r}
    z <- (p1hat - p2hat) / sqrt((1 / 3220 + 1 / 10245) * phat * (1 - phat))
    z
    ```

-   And our $p$-value compares this to the standard normal

    ```{r}
    2 * pnorm(-abs(z))
    ```

- **Exercise**: A study looked at the effects of oral contraceptive (OC) use on heart disease in women 40 to 44 years of age. The researchers found that among 5000 current OC users at baseline, 13 women developed a myocardial infarction (MI) over a 3-year period, whereas among 10,000 never-OC users, 7 developed an MI over a 3-year period. Assess the statistical significance of the results. Do this both "by hand" and using `prop.test()`. State your results.

```{r}
#| echo: false
#| eval: false
prop.test(x = c(13, 7), n = c(5000, 10000)) |>
  tidy()
p1hat <- 13 / 5000
p2hat <- 7 / 10000
phat <- (13 + 7) / (5000 + 10000)
z <- (p1hat - p2hat) / sqrt((1 / 5000 + 1 / 10000) * phat * (1 - phat))
2 * pnorm(-abs(z))

## With continuity correction
# z <- (p1hat - p2hat - 1/10000 - 1/20000) / sqrt((1 / 5000 + 1 / 10000) * phat * (1 - phat))

# We have strong evidence that there is a difference in MI rates between OC users and non-OC users.
```

# Contingency Table Perspective

- In this study design, we collected case women and control women, and measured their age.

- If we would have run the test accidentally assuming that we had collected younger and older women, and measured their cancer status, then it turns out that we would have gotten the **exact same** $p$-value.

  ```{r}
  prop.test(x = c(683, 1498), n = c(3220, 10245))$p.value
  prop.test(x = c(683, 2537), n = c(2181, 11284))$p.value
  ```

- You can consider the binomial test, then, as a test for **association** between two variables that each are binary (categorical with only two categories).

- To run the **equivalent** test of association using a contingency table, first create it using `matrix()`:

  ```{r}
  tab <- matrix(c(683, 1498, 2537, 8747), nrow = 2, ncol = 2, byrow = TRUE)
  dimnames(tab) <- list(Age = c("≥30", "≤29"), Status = c("Case", "Control"))
  tab
  ```
  
- The `dimnames()` code above sets the row names (first) and the column names (second) via a list object.

- Then just plug it into `chisq.test()`.

  ```{r}
  chisq.test(tab) |>
    tidy()
  ```

- **Exercise**: From OC exercise above, insert these data into a 2x2 contingency table. Then run a chi-squared test for homogeneity. Verify that your results are the same as in the first exercise.

```{r}
#| echo: false
#| eval: false
tab <- matrix(c(13, 5000 - 13, 7, 10000 - 7), nrow = 2, byrow = TRUE)
dimnames(tab) <- list(OC = c("Yes", "No"), MI = c("Yes", "No"))
tab
chisq.test(tab) |>
  tidy()
## p-value is the same as above
```

# Fisher's Exact Test

- The above methods are only valid for large $n$ (expected counts at least 5 in *every* cell).

- If this is not a valid assumption, then you can use `fisher.test()` to run an exact test (controls Type I error for all $n$, not just large $n$).

- The syntax is the exact same as `chisq.test()`

  ```{r}
  tab
  fisher.test(tab) |>
    tidy()
  ```
  
- For large $n$, the chi-squared and Fisher tests will provide about the same values. So why use `chisq.test()`? Sometimes, approximate methods can be better. But my opinion is that the stated benefits are minor compared to the benefit of controlling type I error exactly. So I would always use the Fisher test.

- **Exercise**: Researchers collected information on salt diet versus cardiovascular death. Run a Fisher's exact test using the below table to evaluate if diet is associated with cardiovascular death. How does it compare to the chi-squared test?


  ```{r}
  #| message: false
  #| echo: false
  tribble(~`Cause of death`, ~`High salt`, ~`Low salt`,
          "Non-CVD", 2, 23,
          "CVD", 5, 30) |>
    as_tabyl() |>
    adorn_totals(c("col", "row")) |>
    gt(rowname_col = "Cause of death") |>
    tab_spanner(
      columns = 2:3, # select all columns except the row variable
      label = "Type of diet" # the name to display
    ) |>
    tab_stubhead(         # add row variable header
      label = "Cause of death" 
    ) 
  ```


```{r}
#| echo: false
#| eval: false
#| warning: false
tab <- matrix(c(2, 23, 5, 30), nrow = 2, byrow = TRUE)
dimnames(tab) <- list(cause = c("Non-CVD", "CVD"), diet = c("High salt", "Low salt"))
tab
fisher.test(tab) |>
  tidy()
chisq.test(tab) |>
  tidy()

# Same conclusion. No evidence of an association. But p-value is smaller in
# Fisher's exact test.
```

