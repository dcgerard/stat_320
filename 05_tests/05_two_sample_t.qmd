---
title: "Two-sample t-Methods"
author: "David Gerard"
format: html
date: today
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
            fig.width = 4, 
            fig.height = 3, 
            fig.align = "center")
ggplot2::theme_set(ggplot2::theme_bw() + ggplot2::theme(strip.background = ggplot2::element_rect(fill = "white")))
```

```{r}
#| message: false
library(tidyverse)
library(broom)
```


# Paired $t$-tests

- Data from 10 women containt eh systolic blood pressure (SBP) (in mm Hg) before and while using an oral contraceptive. 

  ```{r}
  oc_df <- data.frame(
    pre_sbp = c(115, 112, 107, 119, 115, 138, 126, 105, 104, 115),
    post_sbp = c(128, 115, 106, 128, 122, 145, 132, 109, 102, 117)
  )
  ```

- We use `t.test()` to run a paired $t$-test.
    - `x`: The first column.
    - `y`: The second column. 
    - `paired`: set to `TRUE` to make it a paired $t$-test.

  ```{r}
  t.test(x = oc_df$post_sbp, y = oc_df$pre_sbp, paired = TRUE) |>
    tidy()
  ```

- This is the exact same as just first calculating the differences then running a one-sample $t$-test.

  ```{r}
  oc_df <- mutate(oc_df, diff = post_sbp - pre_sbp)
  t.test(diff ~ 1, data = oc_df) |>
    tidy()
  ```

- Notice that the paired $t$-test uses `x - y`, not `y - x`, as the vector of differences.

- Our conclusion might read like this:

    > We have strong evidence that women who use an oral contraceptive (OC) have a different mean systolic blood pressure (SBP) than women  who do not use an OC ($p$ = 0.008874, $n$ = 10). We estimate that women who use an OC have on average an SBP 4.8 mm Hg higher than women who do not use an OC (95% CI 1.534 mm Hg to 8.066 mm Hg higher).

- **Exercise**: A study included 15 twins where one has schizophrenia and the other does not. These data contain the volume (in cm$^3$) of the left hippocampus of each twin. These data are from *The Statistical Sleuth*, which in turn obtained the data from [doi:10.1056/NEJM199003223221201](https://www.doi.org/10.1056/NEJM199003223221201). Evaluate if there are any physical differences between the twins. Also, provide an interval estimate on the mean difference in volume between twin-types. Do this in two ways (i) by using `t.test()` and (ii) "by hand" after calculating the appropriate summary statistics. 

  ```{r}
  sc_df <- data.frame(
    Unaffected = c(1.94, 1.44, 1.56, 1.58, 2.06, 1.66, 1.75, 1.77, 
                   1.78, 1.92, 1.25, 1.93, 2.04, 1.62, 2.08), 
    Affected = c(1.27, 1.63, 1.47, 1.39, 1.93, 1.26, 1.71, 1.67, 
                 1.28, 1.85, 1.02, 1.34, 2.02, 1.59, 1.97)
  )
  ```


```{r}
#| eval: false
#| echo: false
t.test(x = sc_df$Affected, y = sc_df$Unaffected, paired = TRUE) |>
  tidy()
```

```{block}
#| eval: false
#| echo: false
We have strong evidence of a difference in mean volume between the twin types ($p$ = 0.00602, n = 15). We estimate that the unaffected twin has on average 0.2 cm$^3$ larger hippocampus than the affected twin (95% CI 0.0667 cm$^3$ to 0.3306 cm$^3$ larger).
```

```{r}
#| eval: false
#| echo: false
sc_df <- mutate(sc_df, diff = Affected - Unaffected)
xbar <- mean(sc_df$diff)
s <- sd(sc_df$diff)
n <- nrow(sc_df)
t <- xbar / (s / sqrt(n))
p_value <- 2 * pt(-abs(t), df = n - 1)
lower <- xbar - qt(p = 0.975, df = n - 1) * s / sqrt(n)
upper <- xbar + qt(p = 0.975, df = n - 1) * s / sqrt(n)
c(p_value, lower, upper)
```   

# Unpaired (Equal Variance)

- Consider the lead data that you can read about [here](../data.qmd#lead).

  ```{r}
  #| message: false
  lead <- read_csv("https://dcgerard.github.io/stat_320/data/lead.csv")
  lead <- filter(lead, !is.na(iqf))
  ```

- We are interested in if the exposed and control groups have the same mean full scale IQ. Let's explore the data

  ```{r}
  ggplot(lead, aes(x = Group, y = iqf)) +
    geom_boxplot()
  ```

- Let $X_i$ be the $i$th IQ score in the control group, let $Y_i$ be the $i$th IQ score in the exposed group. 

- Then we assume that $X_i \sim \mathrm{N}(\mu_1, \sigma^2)$ and $Y_i \sim \mathrm{N}(\mu_2, \sigma^2)$, and that all observations are independent.

- We use `t.test()` to run a two-sample $t$-test.
    - The quantitative variable is to the left of the tilde `~`
    - The variable encoding the two groups is to the right of the tilde
    - If we assume equal variances in each group, we set `var.equal = TRUE`

  ```{r}
  t.test(iqf ~ Group, data = lead, var.equal = TRUE) |>
    tidy()
  ```

- We can verify this result manually (you would never do this in real life, but you might on an exam).

  ```{r}
  ## Get summary statistics of the two groups
  lead |>
    group_by(Group) |>
    summarize(mean = mean(iqf), var = var(iqf), n = n()) ->
    sumdf
  xbar <- sumdf$mean[[1]]
  ybar <- sumdf$mean[[2]]
  s2x <- sumdf$var[[1]]
  s2y <- sumdf$var[[2]]
  n1 <- sumdf$n[[1]]
  n2 <- sumdf$n[[2]]
  
  ## Calculate pooled sample standard deviation
  s <- sqrt(((n1 - 1) * s2x + (n2 - 1) * s2y) / (n1 + n2 - 2))
  
  ## Calculate t-statistic
  tstat <- (xbar - ybar) / (s * sqrt(1 / n1 + 1 / n2))
  
  ## compare to t distribution with n1 + n2 - 2 df
  pval <- 2 * pt(-abs(tstat), df = n1 + n2 - 2)
  
  ## Get confidence intervals
  lower <- (xbar - ybar) - qt(0.975, df = n1 + n2 - 2) * s * sqrt(1 / n1 + 1 / n2)
  upper <- (xbar - ybar) + qt(0.975, df = n1 + n2 - 2) * s * sqrt(1 / n1 + 1 / n2)
  
  c(pval = pval, lower = lower, upper = upper)
  ```


- **Exercise**: Is there any difference between exposed and control groups when it comes to the finger-wrist tapping test in dominant hand (`maxfwt`)? Assume equal variances.

```{r}
#| eval: false
#| echo: false
lead <- read_csv("https://dcgerard.github.io/stat_320/data/lead.csv")
lead |>
  filter(!is.na(maxfwt)) |>
  ggplot(aes(x = Group, y = maxfwt)) +
  geom_boxplot()
t.test(maxfwt ~ Group, data = lead, var.equal = TRUE) |> 
  tidy()
## Yes, we have strong evidence of a difference between groups (p = 0.005). 
## We estimate that the control group taps about 7 more times on average
## (95% CI of 1.8 to 12.2 more times).
```

- **Exercise**: A sample of eight 35- to 39-year-old non-pregnant, premenoposaul OC users have a mean systoolic blood pressure (SBP) of 132.82 mm Hg and a sample standard deviation of 15.34 mm Hg. A different sample of 21 non-pregnant, premenopausal, non-OC users have a mean SBP of 127.44 mm Hg and a sample standard deviation of 18.23 mm Hg. What can be said about the underlying mean difference in blood pressure between the two groups? Provide a measure of how sure we are that there is a difference, and provide some interval estimate for this difference. Assume equal variances.

```{r}
#| eval: false
#| echo: false
xbar <- 132.82
s2x <- 15.34^2
n1 <- 8

ybar <- 127.44
s2y <- 18.23^2
n2 <- 21

## Calculate pooled sample standard deviation
s <- sqrt(((n1 - 1) * s2x + (n2 - 1) * s2y) / (n1 + n2 - 2))
tstat <- (xbar - ybar) / (s * sqrt(1 / n1 + 1 / n2))
pval <- 2 * pt(-abs(tstat), df = n1 + n2 - 2)
lower <- (xbar - ybar) - qt(0.975, df = n1 + n2 - 2) * s * sqrt(1 / n1 + 1 / n2)
upper <- (xbar - ybar) + qt(0.975, df = n1 + n2 - 2) * s * sqrt(1 / n1 + 1 / n2)

c(pval = pval, lower = lower, upper = upper)
```

# Test for Equal Variance

- Suppose we have $X_i \sim N(\mu_1, \sigma_1^2)$ and $Y_i \sim N(\mu_2,\sigma_2^2)$. 
- It is possible to test $H_0: \sigma_1 = \sigma_2$ versus $H_1: \sigma_1 \neq \sigma_2$. 

- Folks don't typically do this test because:
    1. It is very sensitive to the normality assumption. Conversely, the $t$-test is not.
    2. The $t$-test with equal variances is relatively robust to violations in the equal variance assumption.
    3. Folks typically just use the unequal variances $t$-test below.

- But if your boss asks you run such a test, use `var.test()`.

  ```{r}
  var.test(iqf ~ Group, data = lead) |>
    tidy()
  ```

- This test is based on the ratio of the variances $s_1^2 / s_2^2$. Under the null, this follows a $F$-distribution with $n_1 - 1$ numerator degrees of freedom and $n_2 - 1$ denominator degrees of freedom.

  ```{r}
  lead |>
    group_by(Group) |>
    summarize(var = var(iqf), n = n()) ->
    sumdf
  var1 <- sumdf$var[[1]]
  var2 <- sumdf$var[[2]]
  n1 <- sumdf$n[[1]]
  n2 <- sumdf$n[[2]]
  
  ## for fstat > 1
  fstat1 <- var1 / var2
  2 * pf(q = fstat1, df1 = n1 - 1, df2 = n2 - 1, lower.tail = FALSE)
  
  ## For fstat < 1
  fstat2 <- var2 / var1
  2 * pf(q = fstat2, df1 = n2 - 1, df2 = n1 - 1, lower.tail = TRUE)
  ```

# Unpaired (Unequal Variance)

- When you don't want to assume equal variances (typically the case), just use the default settings of `t.test()` that has `var.equal = FALSE`.


```{r}
#| message: false
lead <- read_csv("https://dcgerard.github.io/stat_320/data/lead.csv")
lead <- filter(lead, !is.na(iqf))
t.test(iqf ~ Group, data = lead) |>
  tidy()
```
- Don't bother memorizing Satterthwaite's approximation for the degrees of freedom. Just do this in the computer.

- **Exercise**: Is there a difference in finger tapping between groups? Don't assume equal variances.

```{r}
#| message: false
#| echo: false
#| eval: false
lead <- read_csv("https://dcgerard.github.io/stat_320/data/lead.csv")
lead <- filter(lead, !is.na(maxfwt))
t.test(maxfwt ~ Group, data = lead) |>
  tidy()

## Some evidence of a difference (p = 0.01125). Estimate that control 
## group has 7 more taps on average (95% CI of 1.6 to 12.3 more taps on average).
```

# Power and Sample Size Calculations in Two-sample $t$-tests

- Use `power.t.test()`. 

- In the two-sample case, `n` means the sample size **per group**. It assumes the sample sizes are equal, so the total sample size is `2 * n`.

- It also assumes the standard deviations are equal, so you need to use a pooled estimate of the standard deviation.

- If you need more precise power or sample size calculations, then those exist. 
    - But I think these calculations are so much guess work that the error of assuming equal sample sizes is less than the error of the wild guesses you are giving it.

- E.g., suppose we have the OC user exercise above as a pilot experiment.

  ```{r}
  xbar <- 132.82
  s2x <- 15.34^2
  n1 <- 8
  
  ybar <- 127.44
  s2y <- 18.23^2
  n2 <- 21
  ```

- Let's calculate a pooled estimate of the variance, and we will assume that is the true variance for the power calculations.

  ```{r}
  s <- sqrt(((n1 - 1) * s2x + (n2 - 1) * s2y) / (n1 + n2 - 2))
  s
  ```


- Let's suppose we want a power of 0.8. Then the sample size we would need is 168 **per group**:

  ```{r}
  power.t.test(
    delta = xbar - ybar, 
    sd = s, 
    sig.level = 0.05,
    power = 0.8, 
    type = "two.sample")
  ```

- If a researcher can only afford $n = 100$ per gropu, then the power calculation would be 0.58:

  ```{r}
  power.t.test(
    n = 100,
    delta = xbar - ybar, 
    sd = s, 
    sig.level = 0.05,
    type = "two.sample")
  ```

- **Exercise**: Suppose a new drug is proposed to lower intraocular pressure (IOP) among people with glaucoma. It is anticipated that mean IOP will drop by 8 mm Hg after 1 month with the new drug. The comparison group will get the standard drug, which is anticipated to have a mean drop in IOP of 5 mm Hg after 1 month. It is expected that the sd of change within each group will be 10 mm Hg. How many subjects need to be enrolled to achieve 90% power if an equal sample size is planned within each group and a two-sided test with $\alpha$ = 0.05 will be used?

```{r}
#| echo: false
#| eval: false
# 235 subjects per group
power.t.test(delta = 3, sd = 10, sig.level = 0.05, power = 0.9)
```

