---
title: "Chapter 6 Practice Problems"
author: "David Gerard"
date: today
---

These practice problems mostly come from Rosner's publicly available study sheet at the books [companion website](https://www.cengage.com/cgi-wadsworth/course_products_wp.pl?fid=M20b&product_isbn_issn=9781305268920). The solutions are my own, since we differ slightly on what we are looking for in the solutions.

```{r setup}
#| echo: false
#| eval: true
#| message: false
library(tidyverse)
library(gt)
library(broom)
plt_t <- function(
    mu = 0, 
    sig = 1, 
    lb = -Inf,
    ub = Inf,
    df = Inf, 
    rng = c(-3, 3), 
    two_sided = FALSE,
    col = "#E69F00",
    lwd = 1) {
  tibble(x = seq(mu + rng[[1]] * sig, mu + rng[[2]] * sig, length.out = 500)) |>
    mutate(y = dt(x = (x - mu) / sig, df = df)) ->
    df1
  df1 |>
    filter(x > lb, x < ub) ->
    df2
  ggplot() +
    geom_line(data = df1, mapping = aes(x = x, y = y), linewidth = lwd) +
    geom_area(data = df2, mapping = aes(x = x, y = y), fill = col) +
    geom_line(data = df2, mapping = aes(x = x, y = y), color = col, linewidth = lwd) +
    theme_classic() +
    theme(axis.title = element_blank()) ->
    pl
  
  if (two_sided) {
    df1 |>
      filter(x > -ub, x < -lb) ->
      df3
    pl <- pl + 
      geom_area(data = df3, mapping = aes(x = x, y = y), fill = col) +
      geom_line(data = df3, mapping = aes(x = x, y = y), color = col, linewidth = lwd)
  }
  pl
}
plt_binom <- function(
    size, 
    prob = 0.5, 
    lb = -Inf,
    ub = Inf, 
    rng = c(0, size),
    col = "#E69F00",
    valmax = NULL,
    lwd = 1) {
  
  tibble(x = seq(rng[[1]], rng[[2]], by = 1)) |>
    mutate(
      pmf = stats::dbinom(x = x, size = size, prob = prob)
      ) ->
    df
  
  if (is.null(valmax)) {
    df |>
      mutate(col = (x >= lb & x <= ub)) ->
      df
  } else {
    df |>
      mutate(col = y <= stats::dbinom(x = valmax, size = size, prob = prob)) ->
      pmax
  }
  df |>
    ggplot(aes(x = x, xend = x, yend = pmf, color = col)) +
    geom_segment(y = 0, lwd = lwd) +
    theme_classic() +
    theme(axis.title = element_blank()) +
    scale_color_manual(values = c("black", col), guide = "none") +
    scale_x_continuous(breaks = seq(rng[[1]], rng[[2]]))
}
```

## Quantiles

::: {.panel-tabset}
## 6.1 
What is the upper 10th percentile of a chi-square distribution with 5 df?

## Solution
```{r}
qchisq(p = 1 - 0.1, df = 5)
```
:::

::: {.panel-tabset}
## 6.2 
What is the upper 1st percentile of a chi-square distribution with 3 df?

## Solution
```{r}
qchisq(p = 1 - 0.01, df = 3)
```
:::

## Cancer 1

A case-control study of the effectiveness of the Pap smear in preventing cervical cancer (by identifying precancerous lesions) was performed. It was found that 28.1% of 153 cervical-cancer cases and 7.2% of 153 age-matched (within 5 years) controls had never had a Pap smear prior to the time of the case’s diagnosis.

::: {.panel-tabset}
## 6.5 
Provide a 95% CI for the percentage of cervical-cancer cases who never had a Pap test.

## Solution
 Let $X$ be the number of cervical-cancer cases who had never had a Pap-smear. Then $X \sim \mathrm{Binom}(n, p)$. We want a 95% confidence interval for $p$. We are given that $\hat{p} = 0.281$ and $n = 153$. We calculate
$$
\hat{p} \pm z_{1 - \alpha/2} \cdot \sqrt{ \frac{ \hat{p}(1 - \hat{p}) }{n} }
$$
We can get $z_{1-\alpha/2}$ where $\alpha = 0.05$ via
```{r}
qnorm(1 - 0.05/2)
```
Plugging in, we get
$$
0.281 \pm 1.96 \cdot \sqrt{ \frac{ 0.281(1 - 0.281) }{153} }
$$
Numerically, this is
```{r}
0.281 - 1.96 * sqrt(0.281 * (1 - 0.281) / 153)
0.281 + 1.96 * sqrt(0.281 * (1 - 0.281) / 153)
```
:::

::: {.panel-tabset}
## 6.6 
Provide a 95% CI for the percentage of controls who never had a Pap test.

## Solution
This is the exact same thing as 6.5, but with $\hat{p} = 0.072$ and $n = 153$. We get
$$
0.072 \pm 1.96 \cdot \sqrt{ \frac{ 0.072(1 - 0.072) }{153} }
$$
Numerically
```{r}
0.072 - 1.96 * sqrt(0.072 * (1 - 0.072) / 153)
0.072 + 1.96 * sqrt(0.072 * (1 - 0.072) / 153)
```
:::

::: {.panel-tabset}
## 6.7 
Do you think the Pap test is helpful in preventing cervical cancer?

## Solution
Yes. Let $p_1$ is the proportion of cases who did not have a pap-smear and $p_2$ be the proportion of controls who did not have a pap-smear. The confidence interval for $p_2$ is entirely below that of $p_1$. So it is very likely that controls are less likely to not have had a pap-smear than controls. In Chapter 7, we will make this more formal.
:::

## Hypertension

Hypertensive patients are screened at a neighborhood health
clinic and are given methyl dopa, a strong antihypertensive
medication for their condition. They are asked to come back 1
week later and have their blood pressures measured again.
Suppose the initial and follow-up systolic blood pressures of
the patients are given in the following data frame.

```{r}
sbp_data <- tibble(
  patient_number = 1:10,
  initial_sbp = c(200.0, 194.0, 236.0, 163.0, 240.0, 
                  225.0, 203.0, 180.0, 177.0, 240.0),
  followup_sbp = c(188.0, 212.0, 186.0, 150.0, 200.0, 
                   222.0, 190.0, 154.0, 180.0, 225.0)
)
sbp_data
```


To test the effectiveness of the drug, we want to measure the difference ($D$) between initial and follow-up blood pressures for each person.

::: {.panel-tabset}
## 6.8 
What is the mean and sd of $D$?

## Solution
We calculate $D$ with
```{r}
sbp_data |>
  mutate(diff = initial_sbp - followup_sbp) ->
  sbp_data
```
We can now calculate the mean and sd
```{r}
sbp_data |>
  summarize(mean = mean(diff), sd = sd(diff))
```
:::

::: {.panel-tabset}
## 6.9 
What is the standard error of the mean?

## Solution
Rosner means the estimated estimated standard error. This is $s / \sqrt{n}$ where $s$ = 19.85 from 6.8 and $n$ = 10.
```{r}
19.85 / sqrt(10)
```
:::

::: {.panel-tabset}
## 6.10 
Assume that $D$ is normally distributed. Construct a 95% CI for $\mu$.

## Solution
This is
$$
\bar{x} \pm t_{n-1, 1-\alpha/2}\frac{s}{\sqrt{n}}
$$
Where $t_{n-1, 1-\alpha/2}$ with $\alpha = 0.05$ and $n = 10$ is
```{r}
qt(1 - 0.05 / 2, df = 9)
```
Plugging in values
$$
15.1 \pm 2.262 \times 6.277
$$
Numerically
```{r}
15.1 - 2.262 * 6.277
15.1 + 2.262 * 6.277
```

In real-life, we would use `t.test()`.
```{r}
t.test(diff ~ 1, data = sbp_data) |>
  tidy() |>
  select(conf.low, conf.high)
```
:::

::: {.panel-tabset}
## 6.11 
Do you have any opinion on the effectiveness of methyl dopa from the results of these 10 patients?

## Solution
Since 0 is not included in the confidence interval, it is not a likely value. So we have evidence that the mean decrease is positive. But to make claims on efficacy, we would need a control group to see if their mean decrease is also positive by the same amount.
:::

## Cancer 2

Data from U.S. cancer-tumor registries suggest that of all people with the type of lung cancer where surgery is the recommended therapy, 40% survive for 3 years from the time of diagnosis and 33% survive for 5 years.

::: {.panel-tabset}
## 6.12 
Suppose that a group of patients who would have received standard surgery are assigned to a new type of surgery. Of 100 such patients, 55 survive for 3 years and 45 survive for 5 years. Can we say that the new form of surgery is better in any sense than the standard form of surgery?

## Solution
We calculate two lower bounds on proportions (upper confidence intervals). One for the proportion that survive for 3 years ($p_1$) and one for the proportion that survive for 5 years ($p_2$). We will see if the lower bound for $p_1$ is above 0.4 (the national proportion) and the lower bound for $p_2$ is above 0.33 (the national proportion). We are told that $\hat{p}_1 = 55/100 = 0.55$ and $\hat{p}_2 = 45 / 100 = 0.45$. Also, $n = 100$. Both intervals are of the form
$$
\hat{p} - z_{1 - \alpha} \cdot \sqrt{ \frac{ \hat{p}(1 - \hat{p}) }{n} }
$$
Let's use 95% for the level (the standard). Then $z_{1 - 0.05}$ is
```{r}
qnorm(p = 1 - 0.05)
```
The first lower bound is
$$
0.55 - 1.645 \sqrt{ \frac{ 0.55(1 - 0.55) }{100} }
$$
Numerically
```{r}
0.55 - 1.645 * sqrt(0.55 * (1 - 0.55) / 100)
```
The second lower bound is
$$
0.45 - 1.645 \sqrt{ \frac{ 0.45(1 - 0.45) }{100} }
$$
Numerically
```{r}
0.45 - 1.645 * sqrt(0.45 * (1 - 0.45) / 100)
```
Both lower bounds are above their national proportions. So it seems the new surgery is better.
:::

## Cardiovascular Disease 1

A recent hypothesis states that vigorous exercise is an effective preventive measure for subsequent cardiovascular death. To test this hypothesis, a sample of 750 men aged 50–75 who report that they jog at least 10 miles per week is ascertained. After 6 years, 64 have died of cardiovascular disease.

::: {.panel-tabset}
## 6.13 
Compute a 95% CI for the incidence of cardiovascular death in this group.

## Solution
Let $X$ be the number that died. Then $X \sim \mathrm{Binom}(n, p)$. We are told that $n = 750$ and $x = 64$. So $\hat{p} = 64 / 750$. Or
```{r}
64 / 750
```
We want a 95% confidence interval for $p$. The normal approximation should be fine since $np(1-p)\geq 5$.
```{r}
750 * 0.08533 * (1 - 0.08533)
```
The form of the CI is
$$
\hat{p} \pm z_{1 - \alpha/2} \cdot \sqrt{ \frac{ \hat{p}(1 - \hat{p}) }{n} }
$$
We calculate $z_{1 - \alpha/2}$ with $\alpha = 0.05$ to get
```{r}
qnorm(p = 1 - 0.05 / 2)
```
Plugging in values, we get
$$
0.08533 \pm 1.96 \cdot \sqrt{ \frac{ 0.08533(1 - 0.08533) }{750} }
$$
Numerically
```{r}
0.08533 - 1.96 * sqrt(0.08533 * (1 - 0.08533) / 750)
0.08533 + 1.96 * sqrt(0.08533 * (1 - 0.08533) / 750)
```
The real way in R would be
```{r}
prop.test(x = 64, n = 750) |>
  tidy() |>
  select(conf.low, conf.high)
```
This differs slightly than ours because R uses Wilson intervals, while the way in class we learned are Wald intervals.
:::

::: {.panel-tabset}
## 6.14 
If the expected death rate from cardiovascular disease over 6 years in 50–75-year-old men based on large samples is 10%, then can a conclusion be drawn concerning this hypothesis from these data?

## Solution
10% is consistent with these data. So we cannot conclude that exercise is associated with lower death using these data. This holds even if we calculate an upper bound:
```{r}
0.08533 + qnorm(1 - 0.05) * sqrt(0.08533 * (1 - 0.08533) / 750)
```

:::

## Cardiovascular Disease 2

A group of 60 men under the age of 55 with a prior history of myocardial infarction are put on a strict vegetarian diet as part of an experimental program. After 5 years, 3 men from the group have died.

::: {.panel-tabset}
## 6.15 
What is the best point estimate of the 5-year mortality rate in this group of men?

## Solution
If $X$ the number who died out of 60, then $X \sim \mathrm{Binom}(60, p)$. We observe $x = 3$. So,
$$
\hat{p} = 3 / 60 = 0.05
$$
:::

::: {.panel-tabset}
## 6.16
Derive a 95% confidence interval for the 5-yearamortality rate.

## Solution
We cannot use the normal approximation since $n\hat{p}(1 - \hat{p}) < 5$
```{r}
60 * 0.05 * (1 - 0.05)
```
The exact method is
```{r}
binom.test(x = 3, n = 60) |>
  tidy() |>
  select(conf.low, conf.high)
```

This is because if $X \sim \mathrm{Binom}(60, 0.01043)$ then $P(X \geq 3)$ is $\alpha/2 = 0.05/2 = 0.025$:
```{r}
1 - pbinom(q = 2, size = 60, prob = 0.01043)
```
```{r}
#| echo: false
plt_binom(size = 60, prob = 0.01043, lb = 3, rng = c(0, 7))
```

and if $X \sim \mathrm{Binom}(60, 0.1392)$ then $P(X \leq 3)$ is 0.025
```{r}
pbinom(q = 3, size = 60, prob = 0.1392)
```
```{r}
#| echo: false
plt_binom(size = 60, prob = 0.1392, ub = 3, rng = c(0, 20))
```
:::

::: {.panel-tabset}
## 6.17 
Suppose that from a large sample of men under age 55 with a prior history of myocardial infarction, we know that the 5-year mortality rate is 18%. How does the observed mortality rate obtained in Problem 6.15 compare with the large sample rate of 18%?

## Solution
The upper bound of the 95% CI is below 0.18. So we have evidence that those on the vegetarian diet have a lower mortality rate.
:::

## Pulmonary Disease 1

A spirometric tracing is a standard technique used to measure pulmonary function. These tracings represent plots of the volume of air expelled over a 6-second period and tend to look like Figure 6.1. One quantity of interest is the slope at various points along the curve. The slopes are referred to as **flow rates**. A problem that arises is that the flow rates cannot be accurately measured, and some observer error is always introduced. To quantify the observer error, an observer measures the flow at 50% of forced vital capacity (volume as measured at 6 seconds) twice on tracings from 10 different people. A machine called a *digitizer* can trace the curves automatically and can estimate the flow mechanically. Suppose the digitizer is also used to measure the flow twice on these 10 tracings. The data are given in the data frame below.

```{r}
#| echo: false
#| fig-width: 3
#| fig-height: 3
ggplot() + 
  geom_function(fun = log) +
  xlim(1, 5) +
  theme_classic() +
  theme(
    axis.text = element_blank(),
    axis.ticks = element_blank()) +
  xlab("Time (sec)") +
  ylab("Volume (l)") +
  ggtitle("Figure 6.1: A typical\nspirometric tracing")
```


```{r}
flow_rates <- tibble(
  Person = 1:10,
  Manual_replicate1   = c(1.80, 2.01, 1.63, 1.54, 2.21, 4.16, 3.02, 2.75, 3.03, 2.68),
  Manual_replicate2   = c(1.84, 2.09, 1.52, 1.49, 2.36, 4.08, 3.07, 2.80, 3.04, 2.71),
  Digitizer_replicate1 = c(1.82, 2.05, 1.62, 1.49, 2.32, 4.21, 3.08, 2.78, 3.06, 2.70),
  Digitizer_replicate2 = c(1.83, 2.04, 1.60, 1.45, 2.36, 4.27, 3.09, 2.79, 3.05, 2.70)
)
```


::: {.panel-tabset}
## 6.18 
Find a 95% CI for the standard deviation of the difference between the first and second replicates using the manual method.

## Solution
We first calculate the differences
```{r}
flow_rates |>
  mutate(
    Manual_diff = Manual_replicate1 - Manual_replicate2,
    Digitizer_diff = Digitizer_replicate1 - Digitizer_replicate2) ->
  flow_rates
```
We have to assume normality to use the standard variance CI. The following QQ plot seems to say this is an OK assumption:
```{r}
#| fig-width: 3
#| fig-height: 3
ggplot(data = flow_rates, mapping = aes(sample = Manual_diff)) +
  geom_qq() +
  geom_qq_line() +
  theme_bw()
```
The variance CI is of the form
$$
\frac{(n - 1)s^2}{\chi^2_{n-1, 1 - \alpha/2}} \leq \sigma^2 \leq \frac{(n - 1)s^2}{\chi^2_{n-1, \alpha/2}}
$$
$s^2$ is the sample variance
```{r}
summarize(flow_rates, var = var(Manual_diff))
```
$n$ is 10. $\chi^2_{n-1, 1-\alpha/2}$ and $\chi^2_{n-1,\alpha/2}$ are the $1 - \alpha/2$ and $\alpha/2$ quantiels of the chi-squared distribution with $n-1$ degrees of freedom.
```{r}
qchisq(p = c(0.05/2, 1 - 0.05/2), df = 10 - 1)
```
Plugging in values we get
$$
\frac{(10 - 1)0.006068}{19.02} \leq \sigma^2 \leq \frac{(10 - 1)0.006068}{2.70}
$$
Numerically, a 95% CI for the variance
```{r}
9 * 0.006068 / 19.02
9 * 0.006068 / 2.70
```
We take the square root of these to get a 95% CI for the standard deviation
```{r}
sqrt(9 * 0.006068 / 19.02)
sqrt(9 * 0.006068 / 2.70)
```

In real-life, folks would use a bootstrap because of the sensitivity of this CI to the normality assumption
```{r}
set.seed(787)
sdout <- replicate(n = 10000, expr = {
  sd(sample(flow_rates$Manual_diff, replace = TRUE))
})
quantile(sdout, probs = c(0.025, 0.975))
```
:::

::: {.panel-tabset}
## 6.19 
Answer Problem 6.18 for the difference between the first and second replicates using the digitizer method.

## Solution
The sample variance is
```{r}
summarize(flow_rates, var = var(Digitizer_diff))
```
We can just plug in the value using the same equation from 6.18
```{r}
sqrt(9 * 0.0008278 / 19.02)
sqrt(9 * 0.0008278 / 2.70)
```

The bootstrap CI is
```{r}
set.seed(787)
sdout <- replicate(n = 10000, expr = {
  sd(sample(flow_rates$Digitizer_diff, replace = TRUE))
})
quantile(sdout, probs = c(0.025, 0.975))
```

:::

Suppose we want to compare the variability of the two methods within the same person. Let $x_{i1}$ , $x_{i2}$ represent the 2 replicates for the $i$th person using the manual method, and let $y_{i1}, y_{i2}$ represent the 2 replicates for the $i$th person using the digitizer method. Let
$$
d_i = |x_{i1} - x_{i2}| - |y_{i1} - y_{i2}|
$$
Then, $d_i$ is a measure of the difference in variability
using the two methods. Assume that $d_i$ is normally
distributed with mean $\mu_d$ and variance $\sigma_d^2$

::: {.panel-tabset}
## 6.20 
Find a 95% CI for $\mu_d$

## Solution
We need to calculate $d_i$
```{r}
flow_rates |>
  mutate(
    d = abs(Manual_replicate1 - Manual_replicate2) - 
      abs(Digitizer_replicate1 - Digitizer_replicate2)
    ) ->
  flow_rates
```
A 95% CI is of the form
$$
\bar{x} \pm t_{n-1, 1-\alpha/2}\frac{s}{\sqrt{n}}
$$
We can get all of these terms:
```{r}
flow_rates |>
  summarize(
    mean = mean(d), 
    sd = sd(d), 
    n = n(),
    t = qt(p = 1 - 0.05/2, df = n() - 1))
```
Plugging in values we get
$$
0.044	 \pm 2.262\frac{0.03534}{\sqrt{10}}
$$
Numerically
```{r}
0.044 - 2.262 * 0.03534 / sqrt(10)
0.044 + 2.262 * 0.03534 / sqrt(10)
```
The real way in R
```{r}
t.test(d ~ 1, data = flow_rates) |>
  tidy() |>
  select(conf.low, conf.high)
```
:::

::: {.panel-tabset}
## 6.21 
What is your opinion as to the relative variability of the two methods?

## Solution
The confidence interval in part 20 does not include 0. So the average diffrence between replicates is non-zero. In fact, since it is above 0 we have evidence that the Manual way has larger absolute differences on average than the digitizer method.
:::

## Bacteriology

Suppose a group of mice are inoculated with a uniform dose of a specific type of bacteria and all die within 24 days, with the distribution of survival times given in the following data frame.

```{r}
mouse_survival <- tibble(
  survival_time_days = 10:24,
  number_of_mice     = c(5, 11, 29, 30, 40, 51, 71, 65, 48, 36, 21, 12, 7, 2, 1)
)
```

Note that the mean and standard deviation of survival time is
```{r}
#| echo: false
x <- map2(mouse_survival$survival_time_days, 
          mouse_survival$number_of_mice, 
          \(x, y) rep(x = x, each = y)) |>
  unlist()
tibble(
  Mean = mean(x),
  Var = var(x)
  ) |>
  gt()
```


::: {.panel-tabset}
## 6.27
Assume that the underlying distribution of survival times is normal. Estimate the probability $p$ that a mouse will survive for 20 or more days.

## Solution
Let $X$ be the number of day and that $X \sim N(\mu, \sigma^2)$. We want $P(X \geq 20)$. We don't know $\mu$ and $\sigma^2$, but we can use their estimates $\bar{X}$ and $s^2$:
```{r}
1 - pnorm(q = 20, mean = 16.13, sd = sqrt(7.065))
```
Since there is discretezation in the days, it is technically more accurate to use a continuity correction. But don't worry if you forgot this
```{r}
1 - pnorm(q = 19.5, mean = 16.13, sd = sqrt(7.065))
```
:::

::: {.panel-tabset}
## 6.28 
Suppose we are not willing to assume that the underlying distribution is normal. Estimate the probability $p$ that a mouse will survive for 20 or more days.

## Solution
This is just the proportion of mice that survived for 20 or more days.

The total number of mice is
```{r}
mouse_survival |>
  summarize(total = sum(number_of_mice))
```
The number who survived for at least 20 days is
```{r}
mouse_survival |>
  filter(survival_time_days >= 20) |>
  summarize(x = sum(number_of_mice))
```
So $\hat{p} = 43 / 429$ = 0.1002.

:::

::: {.panel-tabset}
## 6.29 
Compute 95% confidence limits for the parameter estimated in Problem 6.28.

## Solution
The interval is of the form
$$
\hat{p} \pm z_{1 - \alpha/2} \cdot \sqrt{ \frac{ \hat{p}(1 - \hat{p}) }{n} }
$$
Where $z_{1 - 0.05/2}$ is
```{r}
qnorm(p = 1 - 0.05 / 2)
```
Plugging in values we get
$$
0.1002 \pm 1.96 \cdot \sqrt{ \frac{ 0.1002(1 - 0.1002) }{429} }
$$
Numerically, this is
```{r}
0.1002 - 1.96 * sqrt(0.1002 * (1 - 0.1002) / 429)
0.1002 + 1.96 * sqrt(0.1002 * (1  - 0.1002) / 429)
```
The real way in R would be
```{r}
prop.test(x = 43, n = 429) |>
  tidy() |>
  select(conf.low, conf.high)
```
:::

::: {.panel-tabset}
## 6.30 
Compute 99% confidence limits for the parameter estimated in Problem 6.28.

## Solution
Now $\alpha = 0.01$, so we need $z_{1 - 0.01 / 2}$
```{r}
qnorm(1 - 0.01 / 2)
```
```{r}
0.1002 - 2.576 * sqrt(0.1002 * (1 - 0.1002) / 429)
0.1002 + 2.576 * sqrt(0.1002 * (1  - 0.1002) / 429)
```
Or, using R
```{r}
prop.test(x = 43, n = 429, conf.level = 0.99) |>
  tidy() |>
  select(conf.low, conf.high)
```

:::

## Cardiovascular Disease 3

In Table 2.1 below, data on serum-cholesterol levels of 24 hospital employees before and after they adopted a vegetarian diet are provided.

```{r}
#| echo: false
#| eval: true
#| message: false

# Create the data frame
cholesterol_data <- tibble::tibble(
  Subject = as.character(1:24),
  Before = c(195, 145, 205, 159, 244, 166, 250, 236, 192, 224, 238, 197, 169, 158, 151, 197, 180, 222, 168, 168, 167, 161, 178, 137),
  After = c(146, 155, 178, 146, 208, 147, 202, 215, 184, 208, 206, 169, 182, 127, 149, 178, 161, 187, 176, 145, 154, 153, 137, 125),
  `Before - After` = Before - After
)

# Add summary statistics
summary_stats <- tibble::tibble(
  Subject = c("Mean", "SD", "n"),
  Before = c(mean(cholesterol_data$Before), sd(cholesterol_data$Before), nrow(cholesterol_data)),
  After = c(mean(cholesterol_data$After), sd(cholesterol_data$After), nrow(cholesterol_data)),
  `Before - After` = c(mean(cholesterol_data$`Before - After`), sd(cholesterol_data$`Before - After`), nrow(cholesterol_data))
)

# Combine data and summary
full_table <- bind_rows(cholesterol_data, summary_stats)

# Create gt table
gt_table <- full_table %>%
  gt() %>%
  tab_header(
    title = "Table 2.1 Serum-Cholesterol levels before and after adopting a vegetarian diet (mg/dL)"
  ) |>
  tab_style(
    style = cell_borders(
      sides = "top",
      color = "black",
      weight = px(2)
    ),
    locations = cells_body(
      rows = Subject == "Mean"
    )
  )


# Print the table
gt_table
```


::: {.panel-tabset}
## 6.31 
What is your best estimate of the effect of adopting a vegetarian diet on change in serum-cholesterol levels?

## Solution
$\bar{X}$: An average difference of 19.54 mg/dL
:::

::: {.panel-tabset}
## 6.32
What is the standard error of the estimate given in Problem 6.31?

## Solution
$$
s / \sqrt{n} = 16.81 / \sqrt{24}
$$
```{r}
16.81 / sqrt(24)
```

:::

::: {.panel-tabset}
## 6.33
Provide a 95% CI for the effect of adopting the diet.

## Solution
The interval is of the form
$$
\bar{x} \pm t_{n-1, 1-\alpha/2}\frac{s}{\sqrt{n}}
$$
We just need $t_{24 - 1, 1 - 0.05 / 2}$
```{r}
qt(p = 1 - 0.05 / 2, df = 24 - 1)
```
Plugging in numbers
$$
19.54 \pm 2.069 \times 3.431
$$
Numerically
```{r}
19.54 - 2.069 * 3.431
19.54 + 2.069 * 3.431
```

:::

::: {.panel-tabset}
## 6.34
What can you conclude from your results in Problem 6.33?

## Solution
We have evidence that cholesterol levels are lower after starting the diet since the 95% CI is above 0.
:::

Some physicians consider only changes of at least 10 mg/dL (the same units as in Table 2.1) to be clinically significant.

::: {.panel-tabset}
## 6.35
Among people with a clinically significant change in either direction, what is the best estimate of the proportion of subjects with a clinically significant decline in cholesterol?

## Solution
You count the number of folks who are less than -10 and the number of folks who are greater than 10. You can do this manually. You end up with 18 greater than 10 and 2 less than -10. Positive numbers mean a decline, so 18 out of 20 clinically significant changes have been a decline, or
$$
\hat{p} = 18/20 = 0.9
$$

:::

::: {.panel-tabset}
## 6.36
Provide a 95% CI associated with the estimate in Problem 6.35.

## Solution
We need to use an exact method since:
```{r}
20 * 0.9 * (1 - 0.9)
```
The exact CI is
```{r}
binom.test(x = 18, n = 20) |>
  tidy() |>
  select(conf.low, conf.high)
```
This is because if $X \sim \mathrm{Binom}(20, 0.683)$ then $P(X \geq 18)$ is $\alpha/2 = 0.05/2 = 0.025$:
```{r}
1 - pbinom(q = 17, size = 20, prob = 0.683)
```
```{r}
#| echo: false
plt_binom(size = 20, prob = 0.683, lb = 18, rng = c(0, 20))
```

and if $X \sim \mathrm{Binom}(20, 0.9877)$ then $P(X \leq 18)$ is 0.025
```{r}
pbinom(q = 18, size = 20, prob = 0.9877)
```
```{r}
#| echo: false
plt_binom(size = 20, prob = 0.9877, ub = 18, rng = c(0, 20))
```
:::

::: {.panel-tabset}
## 6.37
What can you conclude from your results in Problem 6.36?

## Solution
Since the CI is well above 0.5, we can conclude it is more likely that a significant change will result in lower cholestoral than high cholesterol
:::

## Pulmonary Disease 2

Wheezing is a common respiratory symptom reported by both children and adults. A study is conducted to assess whether either personal smoking or maternal smoking are associated with wheezing in children ages 6–19. 

::: {.panel-tabset}
## 6.38 
Suppose that 400 children in this age group whose mothers smoke are assessed in 1985, and it is found that 60 report symptoms of wheezing. Provide a point estimate and a 95% CI for the underlying rate of wheezing in the population of children whose mothers smoke.

## Solution
Let $X$ be the number wheezing out of 400. Then $X \sim \mathrm{Binom}(400, p)$. We estimate $p$ with
$$
\hat{p} = 60 / 400 = 0.15
$$
We obtain a 95% CI of this form:
$$
\hat{p} \pm z_{1 - \alpha/2} \cdot \sqrt{ \frac{ \hat{p}(1 - \hat{p}) }{n} }
$$
We get $z_{1 - \alpha/2}$ with
```{r}
qnorm(1 - 0.05 / 2)
```

Plugging in numbers we get
$$
0.15 \pm 1.96 \sqrt{ \frac{ 0.15(1 - 0.15) }{400} }
$$
Numerically, this is
```{r}
0.15 - 1.96 * sqrt(0.15 * (1 - 0.15) / 400)
0.15 + 1.96 * sqrt(0.15 * (1 - 0.15) / 400)
```
The real way in R is
```{r}
prop.test(x = 60, n = 400) |>
  tidy() |>
  select(conf.low, conf.high)
```
:::

::: {.panel-tabset}
## 6.39 
Suppose the rate of wheezing among children ages 6–19 in the general population is 10%. What can you conclude from the results in Problem 6.38?

## Solution
We have evidence that the rate is higher in children with smoking mothers. This is since the CI from part 6.38 is above 0.1.
:::

::: {.panel-tabset}
## 6.40 
Suppose we have a subgroup of 30 children where both the mother and the child are smokers. Six of these 30 children have wheezing symptoms. Provide a 95% CI for the true rate of wheezing in this population.

## Solution
In this case
$$
\hat{p} = 6 / 30 = 0.2
$$
We need to use an exact method since $n\hat{p}(1 - \hat{p}) < 5$
```{r}
30 * 0.2 * (1 - 0.2)
```
The exact approach results in a 95% CI of
```{r}
binom.test(x = 6, n = 30) |>
  tidy() |>
  select(conf.low, conf.high)
```
This is because if $X \sim \mathrm{Binom}(30, 0.07714)$ then $P(X \geq 6)$ is $\alpha/2 = 0.05/2 = 0.025$:
```{r}
1 - pbinom(q = 5, size = 30, prob = 0.07714	)
```
```{r}
#| echo: false
plt_binom(size = 30, prob = 0.07714	, lb = 6)
```

and if $X \sim \mathrm{Binom}(30, 0.3857)$ then $P(X \leq 6)$ is 0.025
```{r}
pbinom(q = 6, size = 30, prob = 0.3857)
```
```{r}
#| echo: false
plt_binom(size = 30, prob = 0.3857, ub = 6)
```

:::

::: {.panel-tabset}
## 6.41
How do you assess the results in Problem 6.40?

## Solution
We do not have evidence that they have a different wheezing rate than the general population between the CI includes 0.1.
:::

::: {.panel-tabset}
## 6.42
Suppose 6 events are realized over a 1-year period for a random variable that is thought to be Poisson-distributed. Provide a 95% CI for the true expected number of events over 1 year.

## Solution
```{r}
poisson.test(x = 6) |>
  tidy() |>
  select(conf.low, conf.high)
```
:::
